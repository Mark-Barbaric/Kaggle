{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":73291,"databundleVersionId":8930475,"sourceType":"competition"}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Binary Classification of Insurance Selling\n\nThe aim of this workbook is train a model to predict whether customers respond positively to an automobile insurance offer.\n\nurl: https://www.kaggle.com/competitions/playground-series-s4e7/overview","metadata":{}},{"cell_type":"markdown","source":"# Lib Imports","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport dask.dataframe as dd","metadata":{"execution":{"iopub.status.busy":"2024-07-23T12:02:53.242424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.linear_model import LogisticRegressionCV\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.preprocessing import OneHotEncoder, LabelBinarizer, StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"RANDOM_STATE = 32\nY_COLUMN = 'Response'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\nTRAIN_DATASET_DIR = '/kaggle/input/playground-series-s4e7/train.csv' if os.path.exists('/kaggle/input/') else 'train.csv'\nTEST_DATASET_DIR = '/kaggle/input/playground-series-s4e7/test.csv' if os.path.exists('/kaggle/input/') else 'test.csv'\n\nprint(f\"train dataset dir: {TRAIN_DATASET_DIR}\")\nprint(f\"test dataset dir: {TEST_DATASET_DIR}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1. EDA","metadata":{}},{"cell_type":"markdown","source":"### 1.1 Train and Test Dataset Loading\n\nThe aim of this section is to load the train and test datasets, in order to investigate missing data and general trends.","metadata":{}},{"cell_type":"code","source":"train_df = dd.read_csv(TRAIN_DATASET_DIR)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = train_df.compute()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = dd.read_csv(TEST_DATASET_DIR)\ntest_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Train Data Null and Dtype checks","metadata":{}},{"cell_type":"code","source":"train_df.isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Test Data Null and Dtype checks","metadata":{}},{"cell_type":"code","source":"test_df.isna().sum().compute()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There doesn't seem to be any missing or unusual data so we can proceed with the EDA of the training Dataset.","metadata":{}},{"cell_type":"markdown","source":"### 1.2 Train Dataset Feature Engineering\n\nThe first step is to analyse the current dataset to determine if features can be engineered. For starters, I'm going to investigate the object columns to determine whether they can be encoded.","metadata":{}},{"cell_type":"code","source":"train_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['Gender'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are only two values so these can be binary encoded.","metadata":{}},{"cell_type":"code","source":"train_df['Vehicle_Age'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are only three unique values for Vehicle Age, so these can also be encoded.","metadata":{}},{"cell_type":"code","source":"train_df['Vehicle_Damage'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Finally Vehicle Damage can also be binary encoded.","metadata":{}},{"cell_type":"markdown","source":"So to summarize, all of the object columns can be encoded. Vehicle Damage and Gender will be Binary Encoded, and Vehicle Age will be one hot encoded.","metadata":{}},{"cell_type":"code","source":"BINARY_COLS = ['Gender', 'Vehicle_Damage']\nONE_HOT_COLS = ['Vehicle_Age']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_binarizer = LabelBinarizer()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['Gender'] = label_binarizer.fit_transform(train_df['Gender'])\ntrain_df['Vehicle_Damage'] = label_binarizer.fit_transform(train_df['Vehicle_Damage'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vehicle_age_one_hot = pd.get_dummies(train_df['Vehicle_Age'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df_full = pd.concat([train_df.drop('Vehicle_Age', axis=1), vehicle_age_one_hot], axis=1)\ntrain_df_full","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.3 Numerical Col Analysis\n\nThe next step is to review the distribution of numerical columns","metadata":{}},{"cell_type":"code","source":"NUMERICAL_COLS = ['Age', 'Region_Code', 'Annual_Premium', 'Policy_Sales_Channel', 'Vintage']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df_full[NUMERICAL_COLS].hist(bins=20, figsize=(12, 10))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Given the above distributions, it may be worth normalizing these columns.","metadata":{}},{"cell_type":"markdown","source":"### 1.4 Target vs Feature Analysis\n\nThe next step is to review the distribution of the Target Variable, and investigate the relationship between the rest of the features prior to model training.","metadata":{}},{"cell_type":"code","source":"plt.matshow(train_df_full.corr())\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Pipeline Definition and Train Test Split","metadata":{}},{"cell_type":"markdown","source":"Define the preprocessors used for numerical, one hot and binary data.","metadata":{}},{"cell_type":"code","source":"numerical_transformer = Pipeline(\n    steps=[\n        ('ss', StandardScaler())\n    ]\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"binary_transformer = Pipeline(\n    steps=[\n        ('lb', LabelBinarizer())\n    ]\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"one_hot_transformer = Pipeline(\n    steps=[\n        ('oh', OneHotEncoder())\n    ]\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numerical_transformer, NUMERICAL_COLS),\n        ('bin', binary_transformer, BINARY_COLS),\n        ('one_hot', one_hot_transformer, ONE_HOT_COLS)\n    ]\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = train_df.drop(Y_COLUMN, axis=1)\ny = train_df[Y_COLUMN]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr_model = Pipeline(\n    steps=[\n        ('preprocessor', preprocessor),\n        ('classifier', LogisticRegressionCV(Cs=10, cv=4, penalty='l2'))\n    ]\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=RANDOM_STATE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr_model.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}